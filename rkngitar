#!/usr/bin/env python3

# Script to manage storage of uncompressed dump.xml + dump.xml.sig
# in git repo to utilize git delta-compression.
#
# Some metadata is also preserved as part of manifest files and git commit
# messages to simplify grep'ing:
# - size, mtime, MD5, SHA1, SHA256, SHA512 of dump.xml, dump.xml.sig
# - updateTime - both as UNIX time and as raw data
# - updateTimeUrgently - both as UNIX time and as raw data, TZ must match updateTime TZ
# - signingTime (1.2.840.113549.1.9.5) from dump.xml.sig as UNIX time and in updateTime TZ
#
# Metadata of _original_ ZIP file is not preserved and is lost forever.
# Code _hopes_ that mtime of dump.xml{,.sig} is preserved by unzip.

import argparse
import calendar
import codecs
import datetime
import functools
import hashlib
import json
import logging
import os
import re
import sys
import time
import traceback
from contextlib import contextmanager
from subprocess import run, check_call, check_output, Popen, PIPE
from tempfile import TemporaryDirectory

import prometheus_client as prom # https://github.com/prometheus/client_python

from rkndex.const import RKN_EPOCH, ZERO_GIT, ZERO_XML, DUMP_XML, DUMP_SIG, DUMP_ZIP
from rkndex.donor_che import DonorChe
from rkndex.donor_eais import DonorEais
from rkndex.donor_zavod import DonorZavod
from rkndex.gitarlog import GitarLog
from rkndex.util import schedule_every

GITAR_LATENCY = prom.Summary('gitar_duration_seconds', 'Step latency', ['step'])
GITAR_EXCEPTIONS = prom.Counter('gitar_exceptions', 'Step exceptions', ['step'])
GITAR_UPDATETIME = prom.Gauge('gitar_update_time', 'XML updateTime', ['src'])
HEAP_BYTES = prom.Gauge('gitar_heap_bytes', 'Non-packed .git/objects/?? size')
for step in ('todo', 'fetch', 'store', 'upload', 'du', 'repack'):
    GITAR_LATENCY.labels(step)
    GITAR_EXCEPTIONS.labels(step)

OPT = None # CLI options

NAME = 'John Doe'
EMAIL = 'noreply@example.net'
RKN_EMAIL = 'noreply@rkn.gov.ru' # git needs email, but dump.xml.sig has no emails :-(

# Decorator is not used as @H.labels('foo').time() bar is SyntaxError, see following:
# - https://github.com/prometheus/client_python/issues/157
# - https://mail.python.org/pipermail/python-dev/2004-August/046711.html
@contextmanager
def counted_step(step):
    with GITAR_LATENCY.labels(step).time(), GITAR_EXCEPTIONS.labels(step).count_exceptions():
        yield

def git_init():
    if not os.path.exists(OPT.git_dir):
        check_call(['git', 'init', '--bare', OPT.git_dir])
        new = True
    else:
        new = False
    git_zero_ts = '{:d} +0400'.format(RKN_EPOCH)
    os.environ['GIT_DIR'] = os.path.abspath(OPT.git_dir)
    if new:
        check_call(['git', 'config', 'user.name', NAME])
        check_call(['git', 'config', 'user.email', EMAIL])
        tree = check_output(['git', 'hash-object', '-t', 'tree', '/dev/null']).strip()
        commit = check_output(['git', 'commit-tree', '-m', 'Initial commit', tree], env=dict(os.environ,
            GIT_AUTHOR_DATE=git_zero_ts,
            GIT_COMMITTER_DATE=git_zero_ts,
        )).strip()
        check_call(['git', 'update-ref', 'HEAD', commit])
    if not git_blob_exists(ZERO_GIT):
        head = check_output(['git', 'rev-parse', 'HEAD']).strip().decode('ascii')
        zero_git = check_output(['git', 'hash-object', '-w', '--stdin'], input=ZERO_XML).strip().decode('ascii')
        assert zero_git == ZERO_GIT
        check_call(['git', 'read-tree', '--empty'])
        check_call(['git', 'update-index', '--add',
             '--cacheinfo', '100644,{:s},zero.xml'.format(zero_git),
        ])
        tree = check_output(['git', 'write-tree']).strip().decode('ascii')
        commit = check_output(['git', 'commit-tree', '-p', head, '-m', 'Add zero.xml', tree], env=dict(os.environ,
                GIT_COMMITTER_DATE=git_zero_ts,
                GIT_AUTHOR_DATE=git_zero_ts)).strip().decode('ascii')
        check_call(['git', 'update-ref', 'HEAD', commit])
    os.environ['GIT_COMMITTER_NAME'] = NAME
    os.environ['GIT_COMMITTER_EMAIL'] = EMAIL
    os.environ['GIT_AUTHOR_EMAIL'] = RKN_EMAIL
    # GIT_AUTHOR_NAME    ~ CN from dump.xml.sig
    # GIT_AUTHOR_DATE    ~ signingTime from dump.xml.sig
    # GIT_COMMITTER_DATE ~ signingTime

SIGNING_RE = re.compile(br'object: signingTime \(1\.2\.840\.113549\.1\.9\.5\)\s+(?:value\.)?set:\s+UTCTIME:(?P<mon>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+(?P<day>\d+) (?P<hour>\d\d):(?P<min>\d\d):(?P<sec>\d\d) (?P<year>\d{4}) GMT\s', re.DOTALL)
MONMAP = {b'Jan': 1, b'Feb': 2, b'Mar': 3, b'Apr': 4, b'May': 5, b'Jun': 6,
          b'Jul': 7, b'Aug': 8, b'Sep': 9, b'Oct': 10, b'Nov': 11, b'Dec': 12}

def cms_signing_time(cms):
    m = SIGNING_RE.search(cms)
    if m is None:
        raise RuntimeError('Signature file without signingTime')
    d = m.groupdict()
    for k in d.keys():
        if k == 'mon':
            d[k] = MONMAP[d[k]] # NB, it's 1-12, not 0-11
        else:
            d[k] = int(d[k], 10)
    return calendar.timegm((d['year'], d['mon'], d['day'], d['hour'], d['min'], d['sec']))

SUBJECT_DN_RE = re.compile(br'^\s+subject: (?P<s_dn>.*)$', re.MULTILINE)
CN_RE = re.compile(br'\bCN=(?P<cn>.+?)(?:$|, |/street=)') # ugly, but works for now
# SHA1 c574234078c05931b952c930c2163e32b2af8a66 dump.xml.sig mixes `, ` and `/`
# as field separators in subject. That's a funny side-effect of `gost` module.

def cms_subject_cn(cms):
    # Sorry, RFC2253 and RFC4514 are mostly ignored here.
    m = SUBJECT_DN_RE.search(cms)
    if m is None:
        raise RuntimeError('Signature file withoug subject DN')
    dn = m.group('s_dn')
    m = CN_RE.search(dn)
    if m is None:
        raise RuntimeError('Signature file with subject DN without CN', dn)
    cn = m.group('cn') # bytes
    for enc in ('utf-8', 'utf-16-be'): # pure horor suitable only for `git log` :-(
        try:
            val = codecs.escape_decode(cn)[0].decode(enc) # str
        except Exception:
            continue
        if val.isprintable():
            return 'CN=' + val
    raise RuntimeError('CN with strange encoding', cn)

def file_githash(fname):
    h = hashlib.sha1()
    h.update('blob {:d}\0'.format(os.path.getsize(fname)).encode('ascii'))
    with open(fname, 'rb') as fd:
        for blob in iter(functools.partial(fd.read, 65536), b''):
            h.update(blob)
    return h.hexdigest()

def file_metadata(fname):
    blob = hashlib.sha1()
    blob.update('blob {:d}\0'.format(os.path.getsize(fname)).encode('ascii'))
    hashes = [hashlib.md5(), hashlib.sha1(), hashlib.sha256(), hashlib.sha512(), blob]
    with open(fname, 'rb') as fd:
        for blob in iter(functools.partial(fd.read, 65536), b''):
            for h in hashes:
                h.update(blob)
    return {
        'name': os.path.basename(fname),
        'size': os.path.getsize(fname),
        'mtime': int(os.path.getmtime(fname)),
        'MD5': hashes[0].hexdigest(),
        'SHA1': hashes[1].hexdigest(),
        'SHA256': hashes[2].hexdigest(),
        'SHA512': hashes[3].hexdigest(),
        'GIT': hashes[4].hexdigest(),
    }

def git_blob_exists(githash):
    p = run(['git', 'cat-file', '-e', githash])
    if p.returncode == 0:
        return True
    elif p.returncode == 1:
        return False
    else:
        raise RuntimeError('`git cat-file -e` failure', githash, p)

# Non-zero minutes TZ are not tested, so `:00` match is hard-coded
UPDATE_TIME_RE = re.compile(br'\bupdateTime="(?P<raw>(?P<year>\d{4})-(?P<mon>\d\d)-(?P<day>\d\d)T(?P<hour>\d\d):(?P<min>\d\d):(?P<sec>\d\d)\+(?P<tzh>\d\d):00)"')
UPDATE_TIME_URGENTLY_RE = re.compile(br'\bupdateTimeUrgently="(?P<raw>(?P<year>\d{4})-(?P<mon>\d\d)-(?P<day>\d\d)T(?P<hour>\d\d):(?P<min>\d\d):(?P<sec>\d\d)\+(?P<tzh>\d\d):00)"')

def update_timegm(re_match):
    # NB regexps have + offset hardcoded
    s = re_match.groupdict()
    d = {k: int(s[k], 10) for k in s if k != 'raw'}
    tz = datetime.timezone(datetime.timedelta(hours=d['tzh']))
    dt = datetime.datetime(d['year'], d['mon'], d['day'], d['hour'], d['min'], d['sec'], tzinfo=tz)
    return dt, re_match.group('raw').decode('ascii')

def update_time(dump_xml):
    with open(dump_xml, 'rb') as fd:
        head = fd.read(4096)
    m = UPDATE_TIME_RE.search(head)
    if m is None:
        raise RuntimeError('Dump file without updateTime', dump_xml, head)
    ut, utraw = update_timegm(m)
    m = UPDATE_TIME_URGENTLY_RE.search(head)
    if m is None:
        # That's FIXME as http://vigruzki.rkn.gov.ru/docs/description_for_operators_actual.pdf
        # allows that field to be absent.
        raise RuntimeError('FIXME: dump file without updateTimeUrgently', dump_xml, head)
    utu, uturaw = update_timegm(m)
    if ut.tzinfo != utu.tzinfo:
        raise RuntimeError('Insanity, updateTime and updateTimeUrgently in different timezones', utraw, uturaw)
    return ut, utraw, utu, uturaw

def isoformat(unix_ts, tz):
    return datetime.datetime.fromtimestamp(unix_ts, tz).isoformat()

def commit_files(dump_xml, dump_xml_sig, sanity_cb=None):
    cms = check_output(['openssl', 'cms', '-inform', 'DER', '-in', dump_xml_sig, '-cmsout', '-print'])
    signing_ts = cms_signing_time(cms)
    subject_cn = cms_subject_cn(cms)
    verify = Popen(['openssl', 'smime', '-verify', '-engine', 'gost', '-CApath', OPT.capath, '-attime', str(signing_ts),
                    '-in', dump_xml_sig, '-inform', 'DER', '-content', dump_xml, '-out', '/dev/null'], stderr=PIPE)
    # do hashing and sig-check in parallel
    sigmeta = file_metadata(dump_xml_sig)
    xmlmeta = file_metadata(dump_xml)
    ut, utraw, utu, uturaw = update_time(dump_xml)
    if sanity_cb is not None:
        sanity_cb(xmlmeta, sigmeta, ut, utu)
    # back to openssl
    stderr = verify.stderr.read()
    if verify.wait() != 0 or b'Verification successful\n' not in stderr:
        # `stderr` double check is needed because...
        ### $ openssl smime -verify -engine gost -CApath /nonexistent -in dump.xml.sig -inform DER && echo OKAY
        ### engine "gost" set.
        ### smime: Not a directory: /nonexistent
        ### smime: Use -help for summary.
        ### OKAY <--- ^!(*&^%@(^%@#&$%!!!
        # I hope, it has no messages like "Not Quite Verification successful\n"...
        raise RuntimeError('openssl smime -verify failure', signing_ts, stderr) # libengine-gost-openssl1.1 missing?
    # git does not preserve mtime, so mtimes are saved as json manifest all the
    # other fields are preserved, so they're only stored in commit messages.
    mtime_json = [{k: _[k] for k in ('name', 'mtime')} for _ in (xmlmeta, sigmeta)]
    mtime_json = json.dumps(mtime_json, sort_keys=True, separators=(',', ':')).encode('utf-8')
    mtime_blob = check_output(['git', 'hash-object', '-w', '--stdin'], input=mtime_json).strip().decode('ascii')
    xmlblob, sigblob = check_output(['git', 'hash-object', '-w', '--', dump_xml, dump_xml_sig]).strip().decode('ascii').split()
    check_call(['git', 'read-tree', '--empty'])
    signing_utc = time.gmtime(signing_ts)
    check_call(['git', 'update-index', '--add',
         '--cacheinfo', '100644,{:s},meta.json'.format(mtime_blob),
         '--cacheinfo', '100644,{:s},dump.xml'.format(xmlblob),
         '--cacheinfo', '100644,{:s},dump.xml.sig'.format(sigblob),
    ])
    tree = check_output(['git', 'write-tree']).strip().decode('ascii')
    # index is prepared with the proper tree, let's prepare commit
    signing_raw = isoformat(signing_ts, ut.tzinfo)
    body = [
        'Updated {:s}, signed {:s}'.format(utraw, signing_raw),
        '',
        '{:s} {:.0f} updateTime'.format(utraw, ut.timestamp()),
        '{:s} {:.0f} updateTimeUrgently'.format(uturaw, utu.timestamp()),
        '{:s} {:d} signingTime'.format(signing_raw, signing_ts),
        '{:s} {:d} dump.xml mtime'.format(isoformat(xmlmeta['mtime'], ut.tzinfo), xmlmeta['mtime']),
        '{:s} {:d} dump.xml.sig mtime'.format(isoformat(sigmeta['mtime'], ut.tzinfo), sigmeta['mtime']),
    ]
    for h in ('MD5', 'SHA1', 'GIT', 'SHA256', 'SHA512'):
        body.extend((
            '{:s} {:s} dump.xml'.format(h, xmlmeta[h]),
            '{:s} {:s} dump.xml.sig'.format(h, sigmeta[h]),
        ))
    body = '\n'.join(body).encode('utf-8')
    # do the commit, `git-commit` needs working tree, so it's not used
    head = check_output(['git', 'rev-parse', 'HEAD']).strip().decode('ascii')
    git_ts = '{:d} +{:02.0f}00'.format(signing_ts, ut.tzinfo.utcoffset(None).seconds / 3600)
    commit = check_output(['git', 'commit-tree', '-p', head, tree], input=body, env=dict(os.environ,
            GIT_AUTHOR_NAME=subject_cn.encode('utf-8'),
            GIT_COMMITTER_DATE=git_ts,
            GIT_AUTHOR_DATE=git_ts)).strip().decode('ascii')
    check_call(['git', 'update-ref', 'HEAD', commit])

GIT_OBJDIR_RE = re.compile(r'[0-9a-fA-F]{2}')

def objects_heap_size():
    sz = 0
    # enumerating unpacked (or loose) objects
    objdir = os.path.join(OPT.git_dir, 'objects')
    for hh in filter(GIT_OBJDIR_RE.fullmatch, os.listdir(objdir)):
        hhdir = os.path.join(objdir, hh)
        for ff in os.listdir(hhdir):
            sz += os.path.getsize(os.path.join(hhdir, ff))
    return sz

def objects_repack():
    # incremental pack, `git gc` will do full-pack probably...
    check_call(['git', 'repack', '--window-memory={}'.format(OPT.window_memory)])
    check_call(['git', 'prune-packed'])

def donors_loop(gitarlog, eais, donors):
    max_update_time = {don.name: float('-inf') for don in donors}
    for don in schedule_every(donors, 60 / len(donors)):
        try:
            with counted_step('todo'):
                # Only first several handles are taken to cycle through different sources for sure.
                todo = don.list_handles(limit=5)
        except Exception:
            traceback.print_exc(file=sys.stderr)
            todo = []
        sys.stderr.flush() # docker makes stderr buffered for some reason
        for handle in todo:
            try:
                with TemporaryDirectory() as tmpdir:
                    with counted_step('fetch'):
                        xml_binsha256 = don.fetch_xml_and_sig(tmpdir, handle)
                        ut_ts, ut_raw, _, _ = update_time(os.path.join(tmpdir, DUMP_XML))
                        ut_ts = ut_ts.timestamp()
                        max_update_time[don.name] = max(max_update_time[don.name], ut_ts)
                        GITAR_UPDATETIME.labels(don.name).set(max_update_time[don.name])
                        logging.info('%s: fetched xml_sha256 %s, updateTime %s (%d)', don.name, xml_binsha256.hex(), ut_raw, ut_ts)
                    if gitarlog.needs_xml_sha256(xml_binsha256):
                        with counted_step('store'):
                            commit_files(os.path.join(tmpdir, DUMP_XML), os.path.join(tmpdir, DUMP_SIG),
                                         functools.partial(don.sanity_cb, handle))
                            gitarlog.poll_fs()
                            GITAR_UPDATETIME.labels('local').set(gitarlog.max_update_time())
                        logging.info('local: stored xml_sha256 %s, updateTime %s (%d)', xml_binsha256.hex(), ut_raw, ut_ts)
                        with counted_step('du'):
                            sz = objects_heap_size()
                            HEAP_BYTES.set(sz)
                        if OPT.objects_xmx < sz:
                            with counted_step('repack'):
                                objects_repack()
                    if eais.needs_xml_sha256(xml_binsha256) and eais.write_token:
                        with counted_step('upload'):
                            eais.upload(os.path.join(tmpdir, DUMP_ZIP))
                        logging.info('eais: uploaded xml_sha256 %s, updateTime %s (%d)', xml_binsha256.hex(), ut_raw, ut_ts)
            except Exception:
                traceback.print_exc(file=sys.stderr)
            sys.stderr.flush() # docker makes stderr buffered for some reason
        if isinstance(don, DonorEais): # maybe something fresh appeared after `todo`
            max_update_time[don.name] = max(max_update_time[don.name], don.max_update_time())
            GITAR_UPDATETIME.labels(don.name).set(max_update_time[don.name])

def git_size(s):
    suffix = {
        'k': 1024,
        'm': 1024 * 1024,
        'g': 1024 * 1024 * 1024,
    }
    return int(s[:-1]) * suffix[s[-1]] if s.endswith(tuple(suffix.keys())) else int(s)

def parse_args():
    p = argparse.ArgumentParser(description='Importer from EAIS to local git archive')
    p.add_argument('--git-dir', help='Git repo directory', metavar='DIR', required=True)
    p.add_argument('--objects-xmx', help='Git/objects max size to start repack', metavar='SIZE', type=git_size, default='5g')
    p.add_argument('--window-memory', help='Window size for git delta compression', metavar='SIZE', type=git_size, default='384m')
    p.add_argument('--eais-fqdn', help='EAIS service FQDN', metavar='FQDN', required=True)
    p.add_argument('--eais-token', help='EAIS token file', metavar='FILE', required=True)
    p.add_argument('--eais-woken', help='EAIS upload token file', metavar='FILE')
    p.add_argument('--che-url', help='Che file', metavar='URL')
    p.add_argument('--zavod-url', help='Zavod directory', metavar='URL')
    p.add_argument('--zavod-tries', help='Number of tries to fetch from Zavod', metavar='INT', type=int, default=8) # wget's --tries=number is 20 by default
    p.add_argument('--capath', help='CA path with GOST certs', metavar='DIR', required=True)
    p.add_argument('--prom-addr', help='Prometheus exporter bind IP', metavar='IP', default='127.0.0.1')
    p.add_argument('--prom-port', help='Prometheus exporter bind port', metavar='PORT', type=int, required=True)
    return p.parse_args()

def main():
    global OPT
    OPT = parse_args()
    logging.basicConfig(level=logging.INFO)
    git_init()
    with counted_step('du'):
        HEAP_BYTES.set(objects_heap_size())
    gitarlog = GitarLog(OPT.git_dir, os.path.join(OPT.git_dir, 'rkngitar.sqlite'))

    with open(OPT.eais_token) as fd:
        eais_token = fd.read().strip()
    if OPT.eais_woken:
        with open(OPT.eais_woken) as fd:
            write_token = fd.read().strip()
    else:
        write_token = None
    eais = DonorEais(gitarlog.db, OPT.eais_fqdn, eais_token, write_token)
    donors = [eais]
    if OPT.zavod_url:
        donors.append(DonorZavod(gitarlog.db, OPT.zavod_url, OPT.zavod_tries))
    if OPT.che_url:
        donors.append(DonorChe(gitarlog.db, OPT.che_url))

    GITAR_UPDATETIME.labels('local').set(gitarlog.max_update_time())
    # Following may be inaccurate bootstrap, but it is better than 0 or NaN.
    for don in donors:
        GITAR_UPDATETIME.labels(don.name).set(don.max_update_time())

    prom.start_http_server(OPT.prom_port, OPT.prom_addr)
    donors_loop(gitarlog, eais, donors)

if __name__ == '__main__':
    main()
